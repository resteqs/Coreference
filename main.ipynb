{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import time\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "import librosa\n",
    "from transformers import AutoProcessor, AutoModelForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove symbols and special characters from text.\"\"\"\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s\\']', '', text)\n",
    "\n",
    "def convert_conll_to_txt(conll_file, txt_file):\n",
    "    \"\"\"Convert a CoNLL file to a cleaned text file.\n",
    "\n",
    "    - Extracts words from the CoNLL file.\n",
    "    - Cleans the text by removing unwanted characters and extra spaces.\n",
    "    - Writes the cleaned text to an output file.\n",
    "\n",
    "    Args:\n",
    "        conll_file (str): Path to the input CoNLL file.\n",
    "        txt_file \n",
    "    \"\"\"\n",
    "    words = []\n",
    "    \n",
    "    with open(conll_file, 'r', encoding='utf-8') as f_in:\n",
    "        for line in f_in:\n",
    "            if line.strip():  # Non-empty line\n",
    "                tokens = line.strip().split()\n",
    "                if len(tokens) > 3:  # Ensure enough columns\n",
    "                    word = clean_text(tokens[3])  # Clean the word\n",
    "                    if word:  # Only add non-empty words\n",
    "                        words.append(word)\n",
    "            else:\n",
    "                # Add sentence boundary\n",
    "                if words:\n",
    "                    words.append('\\n')\n",
    "    \n",
    "    # Write cleaned text to output file\n",
    "    with open(txt_file, 'w', encoding='utf-8') as f_out:\n",
    "        f_out.write(' '.join(words))\n",
    "\n",
    "\n",
    "def run_mfa_align(input_dir, output_dir):\n",
    "    \"\"\"\"Run the Montreal Forced Aligner (MFA) on the input files.\n",
    "\n",
    "    - Aligns the audio and text files in the input directory.\n",
    "    - Generates a TextGrid file with alignment data.\n",
    "    - Saves the TextGrid file in the output directory.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to the directory containing input files.\n",
    "        output_dir (str): Path to the directory where output files will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure directories exist\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory does not exist: {input_dir}\")\n",
    "        return\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Construct the MFA command\n",
    "    command = [\n",
    "        'mfa', 'align',\n",
    "        input_dir,\n",
    "        'english_mfa',  # Specify the pronunciation dictionary\n",
    "        'english_mfa',  # Specify the acoustic model\n",
    "        output_dir\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(\"Alignment completed successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during alignment: {e}\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"Permission error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "def extract_textgrid_intervals(textgrid_path):\n",
    "    \"\"\"Extract word intervals from a TextGrid file.\n",
    "\n",
    "    - Parses the TextGrid file to extract words and their timing intervals.\n",
    "    - Collects intervals where words are present and skips empty intervals.\n",
    "\n",
    "    Args:\n",
    "        textgrid_file (str): Path to the TextGrid file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries with the following keys:\n",
    "            - 'word' (str): The word from the interval.\n",
    "            - 'start_time' (float): Start time of the interval.\n",
    "            - 'end_time' (float): End time of the interval.\n",
    "    \"\"\"\n",
    "    word_intervals = []\n",
    "    with open(textgrid_path, 'r' ,encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    is_word_tier = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'name = \"words\"' in line:\n",
    "            is_word_tier = True\n",
    "            continue\n",
    "        \n",
    "        # Extract interval data within the words tier with some regex magic\n",
    "        if is_word_tier:\n",
    "            if 'xmin' in line:\n",
    "                xmin = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "            elif 'xmax' in line:\n",
    "                xmax = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "            elif 'text' in line:\n",
    "                text_match = re.search(r'text = \"(.*)\"', line)\n",
    "                text = text_match.group(1).strip() if text_match else \"\"\n",
    "                \n",
    "                # We skip empty text\n",
    "                if text:\n",
    "                    word_intervals.append({\n",
    "                        \"word\": text,\n",
    "                        \"start_time\": xmin,\n",
    "                        \"end_time\": xmax\n",
    "                    })\n",
    "            \n",
    "            if 'name' in line and 'name = ' in line and not 'name = \"words\"' in line:\n",
    "                break\n",
    "    \n",
    "    return word_intervals\n",
    "\n",
    "\n",
    "def verify_mfa_alignment_whisper(audio_file, intervals_from_TxtGrid, model):\n",
    "    \"\"\"Verify MFA alignment using Whisper and return results in a DataFrame.\n",
    "\n",
    "    - Loads a Whisper model for transcription.\n",
    "    - Segments the audio file based on intervals from the TextGrid.\n",
    "    - Transcribes each segment and compares it with the expected word. I checked and whisper fills in the short files with silence to match the correct input shape. \n",
    "     This should not cause any issues\n",
    "    - Saves the results, including execution time and timestamps.\n",
    "\n",
    "    Args:\n",
    "        audio_file (str): Path to the audio file (.wav).\n",
    "        intervals_from_TxtGrid (list): Intervals with words and their timings.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Contains columns:\n",
    "            - 'Correct Word': The expected word from the interval.\n",
    "            - 'Whisper Prediction': The word predicted by Whisper.\n",
    "            - 'Match': 1 if the words match, 0 otherwise.\n",
    "            - 'Start Time': Start time of the interval.\n",
    "            - 'End Time': End time of the interval.\n",
    "            - 'Execution Time': Cumulative time taken up to this point.\n",
    "    \"\"\"\n",
    "    print(\"Loading Whisper model...\")\n",
    "    model = whisper.load_model(model) #--------------------------tiny, base, medium, large, turbo---------------------------------\n",
    "    \n",
    "    # Load audio file\n",
    "    print(f\"Loading audio file: {audio_file}\")\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    \n",
    "    total_words = len(intervals_from_TxtGrid)\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for index, interval in enumerate(intervals_from_TxtGrid, 1):\n",
    "        word = interval[\"word\"]\n",
    "        if not word or word.isspace():\n",
    "            continue\n",
    "            \n",
    "        # Extract time segment\n",
    "        start_ms = int(interval[\"start_time\"] * 1000)\n",
    "        end_ms = int(interval[\"end_time\"] * 1000)\n",
    "        segment = audio[start_ms:end_ms]\n",
    "        \n",
    "        # Process segment\n",
    "        temp_file = \"temp_segment.wav\"\n",
    "        segment.export(temp_file, format=\"wav\")\n",
    "        \n",
    "        # Get Whisper transcription\n",
    "        result = model.transcribe(temp_file)\n",
    "        whisper_text = result[\"text\"].strip().lower()\n",
    "        \n",
    "        # Compare results\n",
    "        mfa_word = word.lower().strip()\n",
    "        is_match = 1 if mfa_word == whisper_text else 0\n",
    "        \n",
    "        exec_time = time.time() - start_time\n",
    "        \n",
    "        # Append to results list\n",
    "        results.append({\n",
    "            'Correct Word': mfa_word,\n",
    "            'Whisper Prediction': whisper_text,\n",
    "            'Match': is_match,\n",
    "            'Start Time': f\"{interval['start_time']:.2f}\",\n",
    "            'End Time': f\"{interval['end_time']:.2f}\",\n",
    "            'Execution Time': f\"{exec_time:.2f}\"\n",
    "        })\n",
    "        \n",
    "        # Remove temp file\n",
    "        os.remove(temp_file)\n",
    "        \n",
    "        # Print progress\n",
    "        progress = (index / total_words) * 100\n",
    "        print(f\"{index}/{total_words} ; {progress:.2f}%\")\n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def align_sequences(conll_words, textgrid_intervals): #Using the Needleman-Wunsch algortihm for alligning sequences, as the files don't fit perfectly\n",
    "    \"\"\"Aligns words from the CoNLL file with words from the TextGrid intervals using the *Needleman-Wunsch* algorithm.\n",
    "\n",
    "    Steps:\n",
    "    1. **Initialization:**\n",
    "       - Create a scoring matrix (`score_matrix`) of size (n+1) x (m+1), where n is the length of `conll_words` and m is the length of `textgrid_words`.\n",
    "       - Initialize the first row and column with cumulative gap penalties to represent alignments with leading gaps.\n",
    "\n",
    "    2. **Scoring Matrix Construction:**\n",
    "       - Iterate over each cell in the matrix to compute the optimal score based on:\n",
    "         - **Match:** If the current words from `conll_words` and `textgrid_words` match, add a positive `match_score`.\n",
    "         - **Mismatch:** If the words do not match, add a negative `mismatch_penalty`.\n",
    "         - **Insertion/Deletion (Gaps):** Assign a negative `gap_penalty` for insertions or deletions.\n",
    "       - Calculate scores for:\n",
    "         - **Diagonal move (match/mismatch):** `score_matrix[i-1][j-1] + score`\n",
    "         - **Up move (deletion in TextGrid):** `score_matrix[i-1][j] + gap_penalty`\n",
    "         - **Left move (insertion in TextGrid):** `score_matrix[i][j-1] + gap_penalty`\n",
    "       - Select the move with the highest score and store it in `score_matrix[i][j]`.\n",
    "       - Record the move direction in the `traceback_matrix` for later path reconstruction.\n",
    "\n",
    "    3. **Traceback:**\n",
    "       - Start from the bottom-right cell of the matrices (`score_matrix[n][m]`).\n",
    "       - Reconstruct the optimal alignment by moving in the direction indicated by `traceback_matrix`:\n",
    "         - **'diag':** Align the current words from both sequences.\n",
    "         - **'up':** Align the word from `conll_words` with a gap (deletion in `textgrid_words`).\n",
    "         - **'left':** Align a gap with the word from `textgrid_words` (insertion in `conll_words`).\n",
    "       - Continue tracing back until reaching the top-left cell.\n",
    "\n",
    "    4. **Results:**\n",
    "       - Obtain `aligned_conll` and `aligned_textgrid`, which are the aligned sequences including gaps ('-') where necessary.\n",
    "       - Collect corresponding time intervals from `textgrid_intervals` for aligned words.\n",
    "       - Reverse the aligned sequences and times to obtain the correct order.\n",
    "\n",
    "    Parameters:\n",
    "        conll_words (list): List of words extracted from the CoNLL file.\n",
    "        textgrid_intervals (list): List of dictionaries from the TextGrid file, each containing:\n",
    "                                   - \"word\": The word string.\n",
    "                                   - \"start_time\": Start time of the interval.\n",
    "                                   - \"end_time\": End time of the interval.\n",
    "\n",
    "    Returns:\n",
    "        aligned_conll (list): Aligned words from the CoNLL file, including gaps.\n",
    "        aligned_textgrid (list): Aligned words from the TextGrid intervals, including gaps.\n",
    "        aligned_times (list): List of (start_time, end_time) tuples corresponding to `aligned_textgrid`.\"\"\"\n",
    "\n",
    "\n",
    "    # lets get Textgrid words and tinestamps\n",
    "    textgrid_words = [str(interval[\"word\"]) for interval in textgrid_intervals]\n",
    "    textgrid_times = [(interval[\"start_time\"], interval[\"end_time\"]) for interval in textgrid_intervals]\n",
    "\n",
    "    # Initialize scoring parameters\n",
    "    match_score = 2\n",
    "    mismatch_penalty = -1\n",
    "    gap_penalty = -2\n",
    "\n",
    "    n = len(conll_words)\n",
    "    m = len(textgrid_words)\n",
    "\n",
    "    # Initialize the scoring matrix\n",
    "    score_matrix = np.zeros((n + 1, m + 1))\n",
    "    traceback_matrix = np.zeros((n + 1, m + 1), dtype='object')\n",
    "\n",
    "    # Initialize first row and column\n",
    "    for i in range(1, n + 1):\n",
    "        score_matrix[i][0] = gap_penalty * i\n",
    "        traceback_matrix[i][0] = 'up'  # Deletion\n",
    "    for j in range(1, m + 1):\n",
    "        score_matrix[0][j] = gap_penalty * j\n",
    "        traceback_matrix[0][j] = 'left'  # Insertion\n",
    "\n",
    "    # Fill in the scoring matrix\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            word1 = conll_words[i - 1].lower()\n",
    "            word2 = textgrid_words[j - 1].lower()\n",
    "\n",
    "            if word1 == word2:\n",
    "                score = match_score\n",
    "            else:\n",
    "                score = mismatch_penalty\n",
    "\n",
    "            diag_score = score_matrix[i - 1][j - 1] + score  # Match/Mismatch\n",
    "            up_score = score_matrix[i - 1][j] + gap_penalty   # Deletion\n",
    "            left_score = score_matrix[i][j - 1] + gap_penalty # Insertion\n",
    "\n",
    "            max_score = max(diag_score, up_score, left_score)\n",
    "            score_matrix[i][j] = max_score\n",
    "\n",
    "            # Traceback pointers\n",
    "            if max_score == diag_score:\n",
    "                traceback_matrix[i][j] = 'diag'\n",
    "            elif max_score == up_score:\n",
    "                traceback_matrix[i][j] = 'up'\n",
    "            else:\n",
    "                traceback_matrix[i][j] = 'left'\n",
    "\n",
    "    # Traceback to get the alignment\n",
    "    aligned_conll = []\n",
    "    aligned_textgrid = []\n",
    "    aligned_times = []\n",
    "    i, j = n, m\n",
    "\n",
    "    while i > 0 or j > 0:\n",
    "        direction = traceback_matrix[i][j]\n",
    "\n",
    "        if direction == 'diag':\n",
    "            aligned_conll.append(conll_words[i - 1])\n",
    "            aligned_textgrid.append(textgrid_words[j - 1])\n",
    "            aligned_times.append(textgrid_times[j - 1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif direction == 'up':\n",
    "            aligned_conll.append(conll_words[i - 1])\n",
    "            aligned_textgrid.append('-')  # Gap in TextGrid\n",
    "            aligned_times.append((None, None))\n",
    "            i -= 1\n",
    "        else:  # 'left'\n",
    "            aligned_conll.append('-')  # Gap in CoNLL\n",
    "            aligned_textgrid.append(textgrid_words[j - 1])\n",
    "            aligned_times.append(textgrid_times[j - 1])\n",
    "            j -= 1\n",
    "\n",
    "    # Reverse the aligned sequences\n",
    "    aligned_conll = aligned_conll[::-1]\n",
    "    aligned_textgrid = aligned_textgrid[::-1]\n",
    "    aligned_times = aligned_times[::-1]\n",
    "\n",
    "    return aligned_conll, aligned_textgrid, aligned_times\n",
    "\n",
    "\n",
    "\n",
    "def add_timestamps_to_conll(conll_path, textgrid_intervals, output_path):\n",
    "    \"\"\"Add timestamps from TextGrid intervals to a CoNLL file.\n",
    "\n",
    "    - Aligns words from the CoNLL file with the intervals from the TextGrid.\n",
    "    - Adds start and end times to each word in the CoNLL file.\n",
    "    - Writes the updated CoNLL data to a new file.\n",
    "\n",
    "    Args:\n",
    "        conll_file (str): Path to the original CoNLL file.\n",
    "        intervals (list): List of intervals extracted from the TextGrid file.\n",
    "        output_conll (str): Path to the output CoNLL file with timestamps.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Define column names matching your CoNLL file structure\n",
    "    column_names = ['col0', 'col1', 'col2', 'word', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', \"col12\"]\n",
    "\n",
    "    # Read the CoNLL file using the adjusted column names\n",
    "    conll_data = pd.read_csv(\n",
    "        conll_path,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=column_names,\n",
    "        skip_blank_lines=True,\n",
    "    )\n",
    "\n",
    "    # Extract the 'word' column\n",
    "    conll_words = conll_data['word'].astype(str).tolist()\n",
    "\n",
    "    # Rest of your code remains the same...\n",
    "    # Align sequences using the conll_words\n",
    "    aligned_conll, aligned_textgrid, aligned_times = align_sequences(conll_words, textgrid_intervals)\n",
    "\n",
    "    # Prepare the output data\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "    for conll_word, times in zip(aligned_conll, aligned_times):\n",
    "        if conll_word != '-':\n",
    "            start_times.append(times[0])  # May be None\n",
    "            end_times.append(times[1])    # May be None\n",
    "\n",
    "    # Add the times to the DataFrame\n",
    "    conll_data = conll_data.loc[conll_data['word'] != '-'].reset_index(drop=True)\n",
    "    conll_data['start_time'] = start_times\n",
    "    conll_data['end_time'] = end_times\n",
    "\n",
    "    # Save the updated data to the output file\n",
    "    conll_data.to_csv(output_path, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    # Optionally, print or log any mismatches or alignments\n",
    "    for idx, (c_word, tg_word) in enumerate(zip(aligned_conll, aligned_textgrid)):\n",
    "        if c_word != tg_word and c_word != '-' and tg_word != '-':\n",
    "            print(f\"Mismatch at position {idx}: CoNLL word '{c_word}' vs. TextGrid word '{tg_word}'\")\n",
    "        elif c_word == '-' or tg_word == '-':\n",
    "            print(f\"Insertion/Deletion at position {idx}: CoNLL word '{c_word}' vs. TextGrid word '{tg_word}'\")\n",
    "\n",
    "\n",
    "def process_files(input_dir, output_dir=None):\n",
    "    \"\"\"Process files in the input directory and prepare them for alignment.\n",
    "\n",
    "    Steps:\n",
    "    - Check for the required files (.conll and .wav) in the input directory.\n",
    "    - Use the output directory if provided; otherwise, default to input directory.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to the directory containing input files.\n",
    "        output_dir (str): Path to the directory where output files will be saved.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contains paths to the following files:\n",
    "            - conll_file (str): Path to the CoNLL file.\n",
    "            - audio_file (str): Path to the audio file.\n",
    "            - txt_file (str): Path to the cleaned text file.\n",
    "            - textgrid_file (str): Path to the TextGrid file generated by MFA.\n",
    "            - output_conll (str): Path to the output CoNLL file with timestamps.\n",
    "    \"\"\"\n",
    "    # Normalize and validate paths\n",
    "    input_dir = os.path.abspath(input_dir)\n",
    "    output_dir = os.path.abspath(output_dir) if output_dir else input_dir\n",
    "\n",
    "    # Validate input directory\n",
    "    if not os.path.isdir(input_dir):\n",
    "        raise ValueError(f\"Input directory does not exist: {input_dir}\")\n",
    "\n",
    "    # Find CoNLL file\n",
    "    conll_files = [f for f in os.listdir(input_dir) if f.endswith('.conll')]\n",
    "    if not conll_files:\n",
    "        raise FileNotFoundError(\"No .conll file found in input directory\")\n",
    "    \n",
    "    # Get base name and construct file paths\n",
    "    base_name = os.path.splitext(conll_files[0])[0]\n",
    "    \n",
    "    # Construct file paths using absolute paths\n",
    "    conll_file = os.path.join(input_dir, conll_files[0])\n",
    "    audio_file = os.path.join(input_dir, f\"{base_name}.wav\")\n",
    "    txt_file = os.path.join(output_dir, f\"{base_name}.txt\")\n",
    "    textgrid_file = os.path.join(output_dir, f\"{base_name}.TextGrid\")\n",
    "    output_conll = os.path.join(output_dir, f\"{base_name}_time.conll\")\n",
    "\n",
    "    # Validate input files exist\n",
    "    if not os.path.isfile(audio_file):\n",
    "        raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "    if not os.path.isfile(conll_file):\n",
    "        raise FileNotFoundError(f\"CoNLL file not found: {conll_file}\")\n",
    "\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return conll_file, audio_file, txt_file, textgrid_file, output_conll\n",
    "\n",
    "def verify_mfa_alignment_mms(audio_file, intervals):\n",
    "\n",
    "\n",
    "    # Load the processor and model\n",
    "    processor = AutoProcessor.from_pretrained(\"mms-meta/mms-zeroshot-300m\")\n",
    "    model = AutoModelForCTC.from_pretrained(\"mms-meta/mms-zeroshot-300m\")\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Load the audio file\n",
    "    speech_array, sampling_rate = librosa.load(audio_file, sr=16000)\n",
    "\n",
    "    results = []\n",
    "    print(\"Starting MMS...\")\n",
    "    length = len(intervals)\n",
    "    for index, interval in enumerate(intervals):\n",
    "        start_time = interval['start_time']\n",
    "        end_time = interval['end_time']\n",
    "        expected_text = interval['word']\n",
    "\n",
    "        # Extract the audio segment\n",
    "        start_sample = int(start_time * sampling_rate)\n",
    "        end_sample = int(end_time * sampling_rate)\n",
    "        audio_segment = speech_array[start_sample:end_sample]\n",
    "\n",
    "        # Prepare input values\n",
    "        inputs = processor(audio_segment, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "        # Get logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "\n",
    "        # Decode the predicted ids to text\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "        # Append the result\n",
    "        results.append({\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'expected_text': expected_text,\n",
    "            'transcribed_text': transcription\n",
    "        })\n",
    "        progress = (index / length) * 100\n",
    "        print(f\"{index}/{length} ; {progress:.2f}%\")\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(\"MMS Done!\")\n",
    "    return df_results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"C:/Users/manto/Documents/Coreference-project-NLP/test3\"\n",
    "output_dir = \"\"\n",
    "\n",
    "if (output_dir == \"\"):\n",
    "    output_dir = input_dir\n",
    "\n",
    "try:\n",
    "        conll_file, audio_file, txt_file, textgrid_file, output_conll = process_files(input_dir, output_dir)\n",
    "        convert_conll_to_txt(conll_file, txt_file) #Uses clean_txt() for removing some chars\n",
    "        run_mfa_align(input_dir, output_dir) #command = ['mfa', 'align', input_dir, (pronounciation model) 'english_mfa',  (accoustic model) english_mfa', output_dir]\n",
    "        intervals = extract_textgrid_intervals(textgrid_file) # Process TextGrid and create time-aligned CoNLL\n",
    "        add_timestamps_to_conll(conll_file, intervals, output_conll) #Adds timestamps from MFA to output_conll file\n",
    "        mmsFrame = verify_mfa_alignment_mms(audio_file, intervals)\n",
    "        #whisperFrame = verify_mfa_alignment_whisper(audio_file, intervals, \"base\") #Verficiation using Whisper Returns a pandaframe\n",
    "        print(f\"Successfully processed files in {input_dir}.Output files saved in: {output_dir} \")\n",
    "except Exception as e:\n",
    "        print(f\"Error processing files: {e}\")\n",
    "\n",
    "print(mmsFrame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
